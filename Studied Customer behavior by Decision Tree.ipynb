{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Science Projectï¼š Studied Customer behavior by Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by Xiaohui(Eartha) Guo\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a Training Set and Training a Decision Tree\n",
    "\n",
    "\n",
    "\n",
    "This is a hands-on task where we build a predictive model using Decision Trees discussed in class. For this part, we will be using the data in `cell2cell_data.csv`.\n",
    "\n",
    "These historical data consist of 39,859 customers: 19,901 customers that churned (i.e., left the company) and 19,958 that did not churn (see the `\"churndep\"` variable). Here are the data set's 11 possible predictor variables for churning behavior: \n",
    "\n",
    "```\n",
    "Pos.  Var. Name  Var. Description\n",
    "----- ---------- --------------------------------------------------------------\n",
    "1     revenue    Mean monthly revenue in dollars\n",
    "2     outcalls   Mean number of outbound voice calls\n",
    "3     incalls    Mean number of inbound voice calls\n",
    "4     months     Months in Service\n",
    "5     eqpdays    Number of days the customer has had his/her current equipment\n",
    "6     webcap     Handset is web capable\n",
    "7     marryyes   Married (1=Yes; 0=No)\n",
    "8     travel     Has traveled to non-US country (1=Yes; 0=No)\n",
    "9     pcown      Owns a personal computer (1=Yes; 0=No)\n",
    "10    creditcd   Possesses a credit card (1=Yes; 0=No)\n",
    "11    retcalls   Number of calls previously made to retention team\n",
    "```\n",
    "\n",
    "The 12th column, the dependent variable `\"churndep\"`, equals 1 if the customer churned, and 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data and prepare it for modeling. Note that the features are already processed for you, so the only thing needed here is split the data into training and testing. Use pandas to create two data frames: train_df and test_df, where train_df has 80% of the data chosen uniformly at random without replacement (test_df should have the other 20%). Also, make sure to write your own code to do the splits. You may use any random() function numpy but DO NOT use the data splitting functions from Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39859, 12)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Code here\n",
    "# read the original data set and add column names\n",
    "names=col_headers_list = ['revenue','outcalls','incalls','months','eqpdays','webcap','marryyes','travel','pcown','creditcd','retcalls','churndep']\n",
    "df = pd.read_csv('/Users/earthaguo/earthaguo/Documents/Introduction to data science/Hw2 March 28/ipython/hw/hw_2/data/cell2cell_data.csv',header=None, names=col_headers_list)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "train_df=df.sample(frac=0.8,random_state=39859)\n",
    "test_df=df.drop(train_df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>outcalls</th>\n",
       "      <th>incalls</th>\n",
       "      <th>months</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>webcap</th>\n",
       "      <th>marryyes</th>\n",
       "      <th>travel</th>\n",
       "      <th>pcown</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>retcalls</th>\n",
       "      <th>churndep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13260</th>\n",
       "      <td>56.07</td>\n",
       "      <td>11.67</td>\n",
       "      <td>2.67</td>\n",
       "      <td>9</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12320</th>\n",
       "      <td>69.63</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>26</td>\n",
       "      <td>467</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10363</th>\n",
       "      <td>66.47</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>13</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18012</th>\n",
       "      <td>50.53</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>30</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>50.74</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       revenue  outcalls  incalls  months  eqpdays  webcap  marryyes  travel  \\\n",
       "13260    56.07     11.67     2.67       9      288       1         0       0   \n",
       "12320    69.63     15.00     1.67      26      467       1         0       1   \n",
       "10363    66.47      3.33     0.67      13      381       1         1       0   \n",
       "18012    50.53      3.00     1.33      30      270       1         1       0   \n",
       "1416     50.74     13.00     0.00      30      900       0         0       0   \n",
       "\n",
       "       pcown  creditcd  retcalls  churndep  \n",
       "13260      1         1         0         1  \n",
       "12320      0         1         0         1  \n",
       "10363      0         1         0         1  \n",
       "18012      0         1         0         1  \n",
       "1416       0         1         0         1  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>outcalls</th>\n",
       "      <th>incalls</th>\n",
       "      <th>months</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>webcap</th>\n",
       "      <th>marryyes</th>\n",
       "      <th>travel</th>\n",
       "      <th>pcown</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>retcalls</th>\n",
       "      <th>churndep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52</td>\n",
       "      <td>1441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>98.47</td>\n",
       "      <td>24.67</td>\n",
       "      <td>3.33</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25.14</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25</td>\n",
       "      <td>743</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44</td>\n",
       "      <td>1324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37.49</td>\n",
       "      <td>18.00</td>\n",
       "      <td>33.67</td>\n",
       "      <td>32</td>\n",
       "      <td>718</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    revenue  outcalls  incalls  months  eqpdays  webcap  marryyes  travel  \\\n",
       "2     29.99      0.00     0.00      52     1441       0         0       0   \n",
       "13    98.47     24.67     3.33      35       13       0         0       1   \n",
       "15    25.14     15.00     1.00      25      743       1         0       0   \n",
       "31    16.14      0.00     0.00      44     1324       0         0       0   \n",
       "37    37.49     18.00    33.67      32      718       1         1       0   \n",
       "\n",
       "    pcown  creditcd  retcalls  churndep  \n",
       "2       1         1         3         1  \n",
       "13      1         1         3         1  \n",
       "15      0         0         2         1  \n",
       "31      0         1         1         1  \n",
       "37      0         1         2         1  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31887, 12)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the shape of training data and testing data\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7972, 12)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39859"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double check the sum of the rows of train and test data\n",
    "7972 + 31887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#it sums up to be the total row number of the origianl data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. If we had to, how would we prove to ourselves or a colleague that our data was indeed randomly sampled on X? And by prove, I mean empirically, not just showing this person our code. Don't actually do the work, just describe in your own words a test you could here. Hint: think about this in terms of selection bias and use notes from our 2nd lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "When sampling is random, the sample mean methods can be used to measure the extent of the variation caused by sampling error. If we know the population mean,  use the bootstrap to generate a confidence interval of the sample mean. we calculate the mean of the sample we generated. If the sample mean we calculated is within the confidence interval, then can can say we are some percent confidence that the sample is random. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Now build and train a decision tree classifier using `DecisionTreeClassifier()` [(manual page)](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) on train_df to predict the `\"churndep\"` target variable. Make sure to use `criterion='entropy'` when instantiating an instance of `DecisionTreeClassifier()`. For all other settings you should use all of the default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Code here\n",
    "clf = DecisionTreeClassifier(criterion='entropy')\n",
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the resulting model from 2.2, show a bar plot of feature names and their feature importance (hint: check the attributes of the `DecisionTreeClassifier()` object directly in IPython or check the manual!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1193c1630>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEtCAYAAAAbeVcBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8lZtnv6moAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11943b0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Code here\n",
    "\n",
    "lab = 'churndep'\n",
    "clf = DecisionTreeClassifier(criterion = 'entropy')\n",
    "clf = clf.fit(train_df.drop(lab, 1), train_df[lab])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.35\n",
    "#ax.bar(train.drop(lab,1).columns.values, clf.feature_importances_, width, color='r')\n",
    "ax.bar(np.arange(11), clf.feature_importances_, width, color = 'r')\n",
    "ax.set_xticks(np.arange(len(clf.feature_importances_)))\n",
    "ax.set_xticklabels(train_df.drop(lab,1).columns.values, rotation = 90)\n",
    "plt.title('Feature Importance')\n",
    "ax.set_ylabel('Normalized Gini Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Is the relationship between the top 3 most important features (as measured here) negative or positive? If your marketing director asked you to explain the top 3 drivers of churn, how would you interpret the relationship between these 3 features and the churn outcome?  What \"real-life\" connection can you draw between each variable and churn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revenue</th>\n",
       "      <th>outcalls</th>\n",
       "      <th>incalls</th>\n",
       "      <th>months</th>\n",
       "      <th>eqpdays</th>\n",
       "      <th>webcap</th>\n",
       "      <th>marryyes</th>\n",
       "      <th>travel</th>\n",
       "      <th>pcown</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>retcalls</th>\n",
       "      <th>churndep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>revenue</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500870</td>\n",
       "      <td>0.391010</td>\n",
       "      <td>-0.015780</td>\n",
       "      <td>-0.221958</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>-0.096705</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>-0.081805</td>\n",
       "      <td>-0.087456</td>\n",
       "      <td>0.015427</td>\n",
       "      <td>-0.013566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outcalls</th>\n",
       "      <td>0.500870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732988</td>\n",
       "      <td>-0.040653</td>\n",
       "      <td>-0.243999</td>\n",
       "      <td>0.112359</td>\n",
       "      <td>-0.125843</td>\n",
       "      <td>-0.039030</td>\n",
       "      <td>-0.091914</td>\n",
       "      <td>-0.098286</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>-0.037233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incalls</th>\n",
       "      <td>0.391010</td>\n",
       "      <td>0.732988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026167</td>\n",
       "      <td>-0.204684</td>\n",
       "      <td>0.092961</td>\n",
       "      <td>-0.094644</td>\n",
       "      <td>-0.037147</td>\n",
       "      <td>-0.076525</td>\n",
       "      <td>-0.078713</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>-0.042031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>months</th>\n",
       "      <td>-0.015780</td>\n",
       "      <td>-0.040653</td>\n",
       "      <td>-0.026167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484487</td>\n",
       "      <td>-0.251660</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.043673</td>\n",
       "      <td>0.061681</td>\n",
       "      <td>0.139435</td>\n",
       "      <td>0.067772</td>\n",
       "      <td>0.022041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eqpdays</th>\n",
       "      <td>-0.221958</td>\n",
       "      <td>-0.243999</td>\n",
       "      <td>-0.204684</td>\n",
       "      <td>0.484487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.394750</td>\n",
       "      <td>0.113467</td>\n",
       "      <td>0.045884</td>\n",
       "      <td>0.071068</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>-0.025709</td>\n",
       "      <td>0.112731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webcap</th>\n",
       "      <td>0.106620</td>\n",
       "      <td>0.112359</td>\n",
       "      <td>0.092961</td>\n",
       "      <td>-0.251660</td>\n",
       "      <td>-0.394750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059369</td>\n",
       "      <td>-0.006382</td>\n",
       "      <td>-0.029652</td>\n",
       "      <td>-0.064909</td>\n",
       "      <td>-0.008354</td>\n",
       "      <td>-0.067481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marryyes</th>\n",
       "      <td>-0.096705</td>\n",
       "      <td>-0.125843</td>\n",
       "      <td>-0.094644</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.113467</td>\n",
       "      <td>-0.059369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150330</td>\n",
       "      <td>0.331503</td>\n",
       "      <td>0.435091</td>\n",
       "      <td>-0.021632</td>\n",
       "      <td>-0.007981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>travel</th>\n",
       "      <td>-0.041864</td>\n",
       "      <td>-0.039030</td>\n",
       "      <td>-0.037147</td>\n",
       "      <td>0.043673</td>\n",
       "      <td>0.045884</td>\n",
       "      <td>-0.006382</td>\n",
       "      <td>0.150330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.254606</td>\n",
       "      <td>0.161626</td>\n",
       "      <td>-0.009184</td>\n",
       "      <td>-0.005919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcown</th>\n",
       "      <td>-0.081805</td>\n",
       "      <td>-0.091914</td>\n",
       "      <td>-0.076525</td>\n",
       "      <td>0.061681</td>\n",
       "      <td>0.071068</td>\n",
       "      <td>-0.029652</td>\n",
       "      <td>0.331503</td>\n",
       "      <td>0.254606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.292806</td>\n",
       "      <td>-0.018081</td>\n",
       "      <td>-0.004160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creditcd</th>\n",
       "      <td>-0.087456</td>\n",
       "      <td>-0.098286</td>\n",
       "      <td>-0.078713</td>\n",
       "      <td>0.139435</td>\n",
       "      <td>0.123862</td>\n",
       "      <td>-0.064909</td>\n",
       "      <td>0.435091</td>\n",
       "      <td>0.161626</td>\n",
       "      <td>0.292806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>-0.014498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retcalls</th>\n",
       "      <td>0.015427</td>\n",
       "      <td>0.012671</td>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.067772</td>\n",
       "      <td>-0.025709</td>\n",
       "      <td>-0.008354</td>\n",
       "      <td>-0.021632</td>\n",
       "      <td>-0.009184</td>\n",
       "      <td>-0.018081</td>\n",
       "      <td>-0.009132</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churndep</th>\n",
       "      <td>-0.013566</td>\n",
       "      <td>-0.037233</td>\n",
       "      <td>-0.042031</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>0.112731</td>\n",
       "      <td>-0.067481</td>\n",
       "      <td>-0.007981</td>\n",
       "      <td>-0.005919</td>\n",
       "      <td>-0.004160</td>\n",
       "      <td>-0.014498</td>\n",
       "      <td>0.070788</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           revenue  outcalls   incalls    months   eqpdays    webcap  \\\n",
       "revenue   1.000000  0.500870  0.391010 -0.015780 -0.221958  0.106620   \n",
       "outcalls  0.500870  1.000000  0.732988 -0.040653 -0.243999  0.112359   \n",
       "incalls   0.391010  0.732988  1.000000 -0.026167 -0.204684  0.092961   \n",
       "months   -0.015780 -0.040653 -0.026167  1.000000  0.484487 -0.251660   \n",
       "eqpdays  -0.221958 -0.243999 -0.204684  0.484487  1.000000 -0.394750   \n",
       "webcap    0.106620  0.112359  0.092961 -0.251660 -0.394750  1.000000   \n",
       "marryyes -0.096705 -0.125843 -0.094644  0.083572  0.113467 -0.059369   \n",
       "travel   -0.041864 -0.039030 -0.037147  0.043673  0.045884 -0.006382   \n",
       "pcown    -0.081805 -0.091914 -0.076525  0.061681  0.071068 -0.029652   \n",
       "creditcd -0.087456 -0.098286 -0.078713  0.139435  0.123862 -0.064909   \n",
       "retcalls  0.015427  0.012671  0.004195  0.067772 -0.025709 -0.008354   \n",
       "churndep -0.013566 -0.037233 -0.042031  0.022041  0.112731 -0.067481   \n",
       "\n",
       "          marryyes    travel     pcown  creditcd  retcalls  churndep  \n",
       "revenue  -0.096705 -0.041864 -0.081805 -0.087456  0.015427 -0.013566  \n",
       "outcalls -0.125843 -0.039030 -0.091914 -0.098286  0.012671 -0.037233  \n",
       "incalls  -0.094644 -0.037147 -0.076525 -0.078713  0.004195 -0.042031  \n",
       "months    0.083572  0.043673  0.061681  0.139435  0.067772  0.022041  \n",
       "eqpdays   0.113467  0.045884  0.071068  0.123862 -0.025709  0.112731  \n",
       "webcap   -0.059369 -0.006382 -0.029652 -0.064909 -0.008354 -0.067481  \n",
       "marryyes  1.000000  0.150330  0.331503  0.435091 -0.021632 -0.007981  \n",
       "travel    0.150330  1.000000  0.254606  0.161626 -0.009184 -0.005919  \n",
       "pcown     0.331503  0.254606  1.000000  0.292806 -0.018081 -0.004160  \n",
       "creditcd  0.435091  0.161626  0.292806  1.000000 -0.009132 -0.014498  \n",
       "retcalls -0.021632 -0.009184 -0.018081 -0.009132  1.000000  0.070788  \n",
       "churndep -0.007981 -0.005919 -0.004160 -0.014498  0.070788  1.000000  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code/answer \n",
    "Correlation = df.corr()\n",
    "Correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Answer: The top 3 most importnat features are \"revenue\", \"eqpdays\" and \"outcalls\". \n",
    "\n",
    "The correlation between \"revenue\" and \"eqpdays\" is -0.221958.\n",
    "\n",
    "So revenue and eqpdays are negatively correlated. \n",
    "\n",
    "The correlation between \"revenue\" and \"outcalls\" is 0.500870.\n",
    "\n",
    "So revenue and outcalls are positively correlated.\n",
    "\n",
    "The correlation between \"eqpdays\" and \"outcalls\" is -0.243999.\n",
    "\n",
    "So eqpdays and outcalls are negatively correlated.\n",
    "\n",
    "The correlation between \"revenue\" and \"churndep\" is -0.013566.\n",
    "\n",
    "So revenue and churndep is negatively correlated. \n",
    "\n",
    "The correlation between \"eqpdays\" and \"churndep\" is 0.112731.\n",
    "\n",
    "So eqpdays and churndep is positively correlated.\n",
    "\n",
    "The correlation between \"outcalls\" and \"churndep\" is -0.037233.\n",
    "\n",
    "So outcalls and churndep is negatively correlated.\n",
    "\n",
    "The real-life connections are: the higher the monthly revenue the customer has, the less possible that the customer churned; the larger the number of days the customer has had his/her current equipment, the more possible that the customer churned; the larger the number of outbound voice calls is, the less possible that the customer churned. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Using the classifier built in 2.2, try predicting `\"churndep\"` on both the train_df and test_df data sets. What is the accuracy on each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import sys\n",
    "\n",
    "#These all need to be installed to both run and visualize a tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15973,     6],\n",
       "       [    0, 15908]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(clf.predict(train_df.drop(lab, 1)), train_df['churndep'])\n",
    "cm \n",
    "# accuracy = (cm[0][0] + cm[1][1]) / float(sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99981183554426567"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1 = (cm[0][0] + cm[1][1]) /(cm[0][0] + cm[1][1] +cm[0][1]+cm[1][0] )\n",
    "ans1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So the prediciton accuray on train_df is around 0.99981."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2143, 1874],\n",
       "       [1842, 2113]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(clf.predict(test_df.drop(lab, 1)), test_df['churndep'])\n",
    "cm2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53386853988961369"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans2 = (cm2[0][0] + cm2[1][1]) /(cm2[0][0] + cm2[1][1] +cm2[0][1]+cm2[1][0] )\n",
    "ans2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So the prediciton accuray on test_df is around 0.531736\n",
    "\n",
    "=====================================================================================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 - Finding a Good Decision Tree\n",
    "The default options for your decision tree may not be optimal. We need to analyze whether tuning the parameters can improve the accuracy of the classifier.  For the following options `min_samples_split` and `min_samples_leaf`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Generate a list of 10 values of each for the parameters mim_samples_split and min_samples_leaf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "\n",
    "\n",
    "#Create a function to calculate prediciton accuracy on test data with min_samples_split_values and min_samples_leaf_values as input\n",
    "def accuracy_test(min_samples_split_values,min_samples_leaf_values):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import scipy as sp\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "    import sys\n",
    "\n",
    "    #These all need to be installed to both run and visualize a tree\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.tree import export_graphviz\n",
    "    from IPython.display import Image\n",
    "    %matplotlib inline\n",
    "    \n",
    "    clf = DecisionTreeClassifier(criterion='entropy', min_samples_split = min_samples_split_values, min_samples_leaf = min_samples_leaf_values )\n",
    "    lab = 'churndep'\n",
    "    clf = clf.fit(train_df.drop(lab, 1), train_df[lab])\n",
    "    cm = confusion_matrix(clf.predict(test_df.drop(lab, 1)), test_df['churndep'])\n",
    "    acc = (cm[0][0] + cm[1][1]) /(cm[0][0] + cm[1][1] +cm[0][1]+cm[1][0] )\n",
    "    \n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53211239337681882"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test whether the function is correct. Compare with the value calculated before. \n",
    "accuracy_test(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59019066733567482"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test multiple times using different pairs of parameters values\n",
    "accuracy_test(300,2200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The lists I generated are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_samples_split_values = [2,1000,2000,3000,4000,5000,6000,7000,8000,10000]\n",
    "min_samples_leaf_values = [1,20,50,80,150,200,300,500,800,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Explain in words your reasoning for choosing the above ranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "First of all I created a function \"accuracy_test(min_samples_split_values,min_samples_leaf_values)\" to calcualte the prediction accuracy with the min_samples_split_values and min_samples_leaf_values as input.\n",
    "\n",
    "Then I used the function to test.\n",
    "\n",
    "Since the goal is to analyze whether tuning the parameters can improve the accuracy of the classifier. So we have better enlarge the range of the min_samples_split_values and min_samples_leaf_values as input so that we could see whether tuning the parameters can improve the accuracy of the classifier obviously. \n",
    "\n",
    "After testing multiple times, I could see the range for min_samples_split_values and min_samples_leaf_values I generated above include the peak prediction, and the range can show the change of the prediction well. So I generate:\n",
    "\n",
    "min_samples_split_values = [2,1000,2000,3000,4000,5000,6000,7000,8000,10000]\n",
    "\n",
    "and\n",
    " \n",
    "min_samples_leaf_values = [1,20,50,80,150,200,300,500,800,1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. For each combination of values in 3.1 (there should be 100), build a new classifier and check the classifier's accuracy on the test data. Plot the test set accuracy for these options. Use the values of `min_samples_split` as the x-axis and generate a new series (line) for each of `min_samples_leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11b0495f8>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOGCYmVleHDDMzCwvDhhmZpaX/w+3vobZO0ktwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11be6c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lab = 'y_buy'\n",
    "\n",
    "# depths = [4, 5, 10, 20]\n",
    "# leaves = np.arange(1, 101)\n",
    "leaf = [1,20,50,80,150,200,300,500,800,1000]\n",
    "split = [2,1000,2000,3000,4000,5000,6000,7000,8000,10000]\n",
    "\n",
    "\n",
    "\n",
    "#Run all of the options\n",
    "run=1\n",
    "if (run == 1):\n",
    "    #Initialize dictionary of results\n",
    "    res = dict()\n",
    "    for d in leaf:\n",
    "        res[d] = list()\n",
    "\n",
    "    #Now train and get results for each option\n",
    "    for d in leaf:\n",
    "        for l in split:\n",
    "            res[d].append(accuracy_test(l,d))\n",
    "            \n",
    "            \n",
    "#Now plot            \n",
    "fig = plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "plt.plot(split,res[leaf[0]], 'b-', label = 'Leaf={}'.format(leaf[0]))\n",
    "plt.plot(split,res[leaf[1]], 'r-', label = 'Leaf={}'.format(leaf[1]))\n",
    "plt.plot(split,res[leaf[2]], 'y-', label = 'Leaf={}'.format(leaf[2]))\n",
    "plt.plot(split,res[leaf[3]], 'g-', label = 'Leaf={}'.format(leaf[3]))\n",
    "plt.plot(split,res[leaf[4]], color = '#eeefff', label = 'Depth={}'.format(leaf[4]))\n",
    "plt.plot(split,res[leaf[5]], 'c-', label = 'Leaf={}'.format(leaf[5]))\n",
    "plt.plot(split,res[leaf[6]], 'm-', label = 'Leaf={}'.format(leaf[6]))\n",
    "plt.plot(split,res[leaf[7]], 'k-', label = 'Leaf={}'.format(leaf[7]))\n",
    "plt.plot(split,res[leaf[8]], 'w-', label = 'Leaf={}'.format(leaf[8]))\n",
    "plt.plot(split,res[leaf[9]], color = '#800000', label = 'Leaf={}'.format(leaf[9]))\n",
    "\n",
    "\n",
    "plt.legend(loc = 10)\n",
    "ax.set_xlabel('Min samples split values')\n",
    "ax.set_ylabel('Accuracy')\n",
    "plt.title('Part 2 Question 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Which configuration returns the best accuracy? What is this accuracy? (Note, if you don't see much variation in the test set accuracy across values of min_samples_split or min_samples_leaf, try redoing the above steps with a different range of values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code here\n",
    "\n",
    "\n",
    "parameters_final = []\n",
    "prediction_final = []\n",
    "for i in range(0,10):\n",
    "    for j in range(0,10):\n",
    "        parameters = (min_samples_split_values[i],min_samples_leaf_values[j])\n",
    "        value = accuracy_test(min_samples_split_values[i],min_samples_leaf_values[j])\n",
    "        parameters_final.append(parameters)\n",
    "        prediction_final.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:10: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(min_samples_split, min_samples_leaf)</th>\n",
       "      <th>prediction_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(1000, 300)</td>\n",
       "      <td>0.596463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>(5000, 1)</td>\n",
       "      <td>0.593954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>(4000, 1)</td>\n",
       "      <td>0.593954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2, 500)</td>\n",
       "      <td>0.593201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(1000, 500)</td>\n",
       "      <td>0.593201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>(5000, 150)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>(5000, 80)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>(5000, 50)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>(5000, 20)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>(4000, 80)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>(4000, 50)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>(4000, 20)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>(4000, 150)</td>\n",
       "      <td>0.593076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1000, 80)</td>\n",
       "      <td>0.592950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>(6000, 50)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>(6000, 200)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>(6000, 150)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>(6000, 80)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>(6000, 1)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>(6000, 500)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>(6000, 300)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>(6000, 20)</td>\n",
       "      <td>0.592323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(3000, 1)</td>\n",
       "      <td>0.591696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2, 300)</td>\n",
       "      <td>0.591696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(2000, 300)</td>\n",
       "      <td>0.591696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>(6000, 1000)</td>\n",
       "      <td>0.591194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(2000, 1)</td>\n",
       "      <td>0.591194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>(3000, 80)</td>\n",
       "      <td>0.591194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(3000, 20)</td>\n",
       "      <td>0.591069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(3000, 50)</td>\n",
       "      <td>0.590943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(1000, 1000)</td>\n",
       "      <td>0.586427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(2000, 1000)</td>\n",
       "      <td>0.586427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2, 1000)</td>\n",
       "      <td>0.586427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(4000, 1000)</td>\n",
       "      <td>0.586427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2, 200)</td>\n",
       "      <td>0.584420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2, 150)</td>\n",
       "      <td>0.583668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(2, 80)</td>\n",
       "      <td>0.581786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>(10000, 1)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>(10000, 150)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>(10000, 20)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>(10000, 50)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>(10000, 80)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(10000, 500)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>(10000, 200)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>(10000, 300)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(10000, 800)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>(8000, 800)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>(8000, 1000)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>(10000, 1000)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>(8000, 500)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>(8000, 300)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>(8000, 200)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>(8000, 150)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>(8000, 80)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>(8000, 50)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>(8000, 20)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>(8000, 1)</td>\n",
       "      <td>0.578149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2, 50)</td>\n",
       "      <td>0.570120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, 20)</td>\n",
       "      <td>0.561841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>0.532865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   (min_samples_split, min_samples_leaf)  prediction_accuracy\n",
       "16                           (1000, 300)             0.596463\n",
       "50                             (5000, 1)             0.593954\n",
       "40                             (4000, 1)             0.593954\n",
       "7                               (2, 500)             0.593201\n",
       "17                           (1000, 500)             0.593201\n",
       "54                           (5000, 150)             0.593076\n",
       "53                            (5000, 80)             0.593076\n",
       "52                            (5000, 50)             0.593076\n",
       "51                            (5000, 20)             0.593076\n",
       "43                            (4000, 80)             0.593076\n",
       "42                            (4000, 50)             0.593076\n",
       "41                            (4000, 20)             0.593076\n",
       "44                           (4000, 150)             0.593076\n",
       "13                            (1000, 80)             0.592950\n",
       "62                            (6000, 50)             0.592323\n",
       "65                           (6000, 200)             0.592323\n",
       "64                           (6000, 150)             0.592323\n",
       "63                            (6000, 80)             0.592323\n",
       "60                             (6000, 1)             0.592323\n",
       "67                           (6000, 500)             0.592323\n",
       "66                           (6000, 300)             0.592323\n",
       "61                            (6000, 20)             0.592323\n",
       "30                             (3000, 1)             0.591696\n",
       "6                               (2, 300)             0.591696\n",
       "26                           (2000, 300)             0.591696\n",
       "69                          (6000, 1000)             0.591194\n",
       "20                             (2000, 1)             0.591194\n",
       "33                            (3000, 80)             0.591194\n",
       "31                            (3000, 20)             0.591069\n",
       "32                            (3000, 50)             0.590943\n",
       "..                                   ...                  ...\n",
       "19                          (1000, 1000)             0.586427\n",
       "29                          (2000, 1000)             0.586427\n",
       "9                              (2, 1000)             0.586427\n",
       "49                          (4000, 1000)             0.586427\n",
       "5                               (2, 200)             0.584420\n",
       "4                               (2, 150)             0.583668\n",
       "3                                (2, 80)             0.581786\n",
       "90                            (10000, 1)             0.578149\n",
       "94                          (10000, 150)             0.578149\n",
       "91                           (10000, 20)             0.578149\n",
       "92                           (10000, 50)             0.578149\n",
       "93                           (10000, 80)             0.578149\n",
       "97                          (10000, 500)             0.578149\n",
       "95                          (10000, 200)             0.578149\n",
       "96                          (10000, 300)             0.578149\n",
       "98                          (10000, 800)             0.578149\n",
       "88                           (8000, 800)             0.578149\n",
       "89                          (8000, 1000)             0.578149\n",
       "99                         (10000, 1000)             0.578149\n",
       "87                           (8000, 500)             0.578149\n",
       "86                           (8000, 300)             0.578149\n",
       "85                           (8000, 200)             0.578149\n",
       "84                           (8000, 150)             0.578149\n",
       "83                            (8000, 80)             0.578149\n",
       "82                            (8000, 50)             0.578149\n",
       "81                            (8000, 20)             0.578149\n",
       "80                             (8000, 1)             0.578149\n",
       "2                                (2, 50)             0.570120\n",
       "1                                (2, 20)             0.561841\n",
       "0                                 (2, 1)             0.532865\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat and sorted dataframe to find the prediciton and parameteres in descending order.\n",
    "parameter_prediciton_accuracy_final = []\n",
    "for i in range(0,100):\n",
    "    value = (parameters_final[i], prediction_final[i])\n",
    "    parameter_prediciton_accuracy_final.append(value)\n",
    "parameter_prediciton_accuracy_final\n",
    "\n",
    "parameter_prediciton_accuracy_final_df = pd.DataFrame(parameter_prediciton_accuracy_final, columns=[\"(min_samples_split, min_samples_leaf)\", \"prediction_accuracy\"])  \n",
    "\n",
    "parameter_prediciton_accuracy_final_df_sorted = parameter_prediciton_accuracy_final_df.sort('prediction_accuracy', ascending=False)\n",
    "\n",
    "parameter_prediciton_accuracy_final_df_sorted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Answer:\n",
    "From the table above we can see that when \"min_samples_split = 1000\" and \"min_samples_leaf = 300\", we get the best accuracy.\n",
    "\n",
    "The accuracy is 0.596463.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. If you were working for a marketing department, how would you use your churn production model in a real business environment? Explain why churn prediction might be good for the business and how one might improve churn by using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "The top three features that influence churn are eqpdays, revenue and outcalls.\n",
    "\n",
    "Here: the definition of the three features are:\n",
    "\n",
    "eqpdays: Number of days the customer has had his/her current equipment\n",
    "\n",
    "revenue: Mean monthly revenue in dollars\n",
    "\n",
    "outcalls: Mean number of outbound voice calls\n",
    "\n",
    "Revenue and churndep is negatively correlated, eqpdays and churndep is positively correlated, and outcalls and churndep is negatively correlated.\n",
    "\n",
    "So in order to keep more customers, we had better to provide products that could attract customers with high revenue and who have more outcalls. The customers had better has less eqdays. Then the churned would happen less. \n",
    "\n",
    "We also analyzed that revenue and eqpdays are negatively correlated,revenue and outcalls are positively correlated, and eqpdays and outcalls are negatively correlated. So it is very easy to recognize which customers are less likely to churn. We could focus on the revenue of a customers. If a customer has high revenue, he or she is less likely to churn. \n",
    "\n",
    "Churn prediction is good for the business. So the company could predict in advance which customer would leave the company and try to keep the customer before he or she leavse. \n",
    "\n",
    "When predicting churn we use the decision tree classifier with 'entropy'as the criterion, and set \"min_samples_split = 1000\" and \"min_samples_leaf = 300\". Then we could have the highest churn prediction accuracy. With the help of prediction, the company would keep more costomers.  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
